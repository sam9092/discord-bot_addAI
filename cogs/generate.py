from discord.ext import commands
import discord
import torch
import random
import tempfile
import os
import gc
from diffusers import StableDiffusionPipeline
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()
api_key = os.getenv("api_key")
model = "meta-llama/llama-4-scout-17b-16e-instruct"

client = OpenAI(
    api_key=api_key,
    base_url="https://api.groq.com/openai/v1"
)

system = "Translate the user's prompt into concise, fluent English suitable for text-to-image generation. Do not add explanations or suggestions. Output only the translated prompt."
def translate_2_English(user_prompt):
    messages = [
        {"role": "system", "content": system},
        {"role": "user", "content": user_prompt}
    ]
    response = client.chat.completions.create(
        model=model,
        messages=messages,
        temperature=0.4
    )
    return response.choices[0].message.content.strip()

class ImageGen(commands.Cog):
    def __init__(self, bot: commands.Bot):
        self.bot = bot
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"ğŸ–¼ï¸ å•Ÿç”¨ç”Ÿåœ–åŠŸèƒ½ï¼Œä½¿ç”¨è¨­å‚™ï¼š{self.device}")

        self.pipe = StableDiffusionPipeline.from_pretrained(
            "nitrosocke/Ghibli-Diffusion",
            torch_dtype=torch.float16 if self.device == "cuda" else torch.float32
        ).to(self.device)

    def generate_images(self, prompt, enhance_text, negative_text):
        seed = random.randint(0, 2**32 - 1)
        generator = torch.Generator(self.device).manual_seed(seed)

        translated_prompt = translate_2_English(prompt)
        final_prompt = f"{translated_prompt}, {enhance_text}"

        gc.collect()
        if self.device == "cuda":
            torch.cuda.empty_cache()

        with torch.no_grad():
            image = self.pipe(
                prompt=final_prompt,
                negative_prompt=negative_text,
                height=512,
                width=512,
                num_inference_steps=20,
                guidance_scale=7.5,
                generator=generator
            ).images[0]

        return image, seed, translated_prompt

    @commands.command(name="ç”Ÿåœ–")
    async def generate_command(self, ctx: commands.Context, *, prompt: str):
        await ctx.send("ğŸ§ª æ”¶åˆ°ç”Ÿæˆè«‹æ±‚ï¼Œè«‹ç¨ç­‰5åˆ†é˜å·¦å³...")

        try:
            # é è¨­å¢å¼·èˆ‡è² é¢æç¤º
            enhance_text = "Masterpiece, Ultra High Quality, Cinematic Light, Ghibli Style"
            negative_text = "bad anatomy, deformed, extra fingers, blurry, worst quality"

            image, seed, translated = self.generate_images(prompt, enhance_text, negative_text)

            with tempfile.NamedTemporaryFile(suffix=".png", delete=False) as f:
                image.save(f.name)
                file = discord.File(f.name, filename=f"generated_{seed}.png")

            await ctx.send(
                content=f"âœ… **åœ–ç‰‡ç”Ÿæˆå®Œæˆï¼**\nä½¿ç”¨çš„prompt: `{translated}`",
                file=file
            )

            os.unlink(f.name)

        except Exception as e:
            await ctx.send(f"âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

async def setup(bot: commands.Bot):
    await bot.add_cog(ImageGen(bot))
